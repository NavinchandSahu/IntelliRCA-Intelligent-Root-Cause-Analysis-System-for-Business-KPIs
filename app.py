# app.py
# Intelligent Root Cause Analysis System
# Author: Navinchand Sahu

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
import os
from urllib.parse import quote, unquote
from db_mysql import fetch_upload_history, save_upload

st.set_page_config(page_title="Intelligent RCA System", layout="wide")

# =========================
# AXIS FONT SIZE (FIXED = 10)
# =========================
def style_axis(ax):
    ax.tick_params(axis="x", labelsize=5)
    ax.tick_params(axis="y", labelsize=5)
    ax.xaxis.label.set_size(7)
    ax.yaxis.label.set_size(7)
    ax.title.set_size(9)

def chart_desc(text):
    st.markdown(
        f"<p style='font-size:16px; color:black;'>{text}</p>",
        unsafe_allow_html=True
    )

# =========================
# CORE ANALYSIS FUNCTION
# =========================
def run_analysis(df):

    st.subheader("üìå Key Performance Indicators")
    df["Profit"] = df["Revenue"] - df["Cost"]

    c1, c2, c3 = st.columns(3)
    c1.metric("Total Revenue", f"‚Çπ {df['Revenue'].sum():,.0f}")
    c2.metric("Total Cost", f"‚Çπ {df['Cost'].sum():,.0f}")
    c3.metric("Total Profit", f"‚Çπ {df['Profit'].sum():,.0f}")

    # =========================
    # PROFIT TREND
    # =========================
    if "Date" in df.columns:
        st.subheader("üìà Profit Trend Over Time")
        chart_desc("Shows how total profit changes across different dates.")

        w = st.number_input("Trend Width (+ / -)", 1, 20, 5, 1, key="trend_w")
        h = st.number_input("Trend Height (+ / -)", 1, 15, 3, 1, key="trend_h")

        df["Date"] = pd.to_datetime(df["Date"])
        trend = df.groupby("Date")["Profit"].sum()

        fig, ax = plt.subplots(figsize=(w, h))
        ax.plot(trend.index, trend.values)
        ax.set_xlabel("Date")
        ax.set_ylabel("Profit")
        ax.set_title("Profit Trend")
        style_axis(ax)
        st.pyplot(fig)

    # =========================
    # PRODUCT PROFIT BAR
    # =========================
    if "Product" in df.columns:
        st.subheader("üìä Product-wise Profit")
        chart_desc("Compares profit generated by each product.")

        w = st.number_input("Bar Width (+ / -)", 1, 20, 4, 1, key="bar_w")
        h = st.number_input("Bar Height (+ / -)", 1, 15, 3, 1, key="bar_h")

        bar = df.groupby("Product")["Profit"].sum()

        fig, ax = plt.subplots(figsize=(w, h))
        bar.plot(kind="bar", ax=ax)
        ax.set_xlabel("Product")
        ax.set_ylabel("Profit")
        ax.set_title("Product-wise Profit")
        ax.tick_params(axis="x", rotation=45)
        style_axis(ax)
        st.pyplot(fig)

    # =========================
    # FACTOR IMPACT BAR
    # =========================
    st.subheader("üìä Factors Impacting Revenue")
    chart_desc("Shows which numeric factors influence revenue the most.")

    numeric_cols = df.select_dtypes(include=np.number).columns.drop("Revenue", errors="ignore")
    impact = {col: df[col].corr(df["Revenue"]) for col in numeric_cols}
    impact = pd.Series(impact).dropna().sort_values(key=abs, ascending=False)

    w = st.number_input("Impact Bar Width (+ / -)", 1, 20, 4, 1, key="impact_w")
    h = st.number_input("Impact Bar Height (+ / -)", 1, 15, 3, 1, key="impact_h")

    fig, ax = plt.subplots(figsize=(w, h))
    impact.plot(kind="bar", ax=ax)
    ax.set_xlabel("Factor")
    ax.set_ylabel("Correlation with Revenue")
    ax.set_title("Revenue Drivers")
    ax.tick_params(axis="x", rotation=45)
    style_axis(ax)
    st.pyplot(fig)

    # =========================
    # PIE CHART
    # =========================
    if "Product" in df.columns:
        st.subheader("ü•ß Product Contribution")
        chart_desc("Shows percentage contribution of each product to total profit.")

        w = st.number_input("Pie Width (+ / -)", 1, 15, 3, 1, key="pie_w")
        h = st.number_input("Pie Height (+ / -)", 1, 15, 3, 1, key="pie_h")

        data = df.groupby("Product")["Profit"].sum()
        data = data[data > 0]

        fig, ax = plt.subplots(figsize=(w, h))
        ax.pie(data, labels=data.index, autopct="%1.1f%%", startangle=90)
        ax.axis("equal")
        ax.set_title("Profit Contribution")
        st.pyplot(fig)

    # =========================
    # SCATTER
    # =========================
    if {"Region", "Product", "Sales"}.issubset(df.columns):
        st.subheader("üìç Product Popularity by Region")
        chart_desc("Shows which products are popular in which regions based on sales.")

        w = st.number_input("Scatter Width (+ / -)", 1, 20, 4, 1, key="sc_w")
        h = st.number_input("Scatter Height (+ / -)", 1, 15, 3, 1, key="sc_h")

        fig, ax = plt.subplots(figsize=(w, h))
        for product in df["Product"].unique():
            temp = df[df["Product"] == product]
            ax.scatter(temp["Region"], temp["Sales"], label=product)

        ax.set_xlabel("Region")
        ax.set_ylabel("Sales")
        ax.set_title("Product Sales by Region")
        ax.legend(fontsize=6)
        style_axis(ax)
        st.pyplot(fig)

    # =========================
    # HISTOGRAM
    # =========================
    st.subheader("üìä Profit Distribution")
    chart_desc("Shows distribution of profit values.")

    w = st.number_input("Histogram Width (+ / -)", 1, 20, 4, 1, key="hist_w")
    h = st.number_input("Histogram Height (+ / -)", 1, 15, 3, 1, key="hist_h")

    fig, ax = plt.subplots(figsize=(w, h))
    ax.hist(df["Profit"], bins=30)
    ax.set_xlabel("Profit")
    ax.set_ylabel("Frequency")
    ax.set_title("Profit Distribution")
    style_axis(ax)
    st.pyplot(fig)

    # =========================
    # ANOMALY DETECTION
    # =========================
    st.subheader("üö® Anomaly Detection")
    if len(df) > 10:
        iso = IsolationForest(contamination=0.15, random_state=42)
        df["Anomaly"] = iso.fit_predict(df[["Profit"]])
        st.dataframe(df[df["Anomaly"] == -1])

    # =========================
    # BUSINESS INSIGHTS (EXTENDED ‚Äì KEEP + ADD)
    # =========================
    st.subheader("üí° Business Insights")

    # ---------- EXISTING INSIGHTS (KEEP AS IS) ----------
    loss_ratio = (df["Profit"] < 0).mean()

    if loss_ratio > 0.4:
        st.warning("‚ö†Ô∏è High loss-making transactions")
    elif loss_ratio > 0.2:
        st.warning("‚ö†Ô∏è Moderate losses detected")
    else:
        st.success("‚úÖ Business is largely profitable")

    corr = df.select_dtypes(include=np.number).corr()["Profit"].drop("Profit")
    if not corr.empty:
        st.info(f"üìà Strongest Profit Driver: {corr.idxmax()}")
        st.info(f"üìâ Strongest Loss Driver: {corr.idxmin()}")

    # ---------- NEW INSIGHTS (ADDED, NO CONFLICT) ----------
    if "Product" in df.columns:

        # Determine popularity metric
        popularity_metric = None
        if "Sales" in df.columns:
            popularity_metric = "Sales"
        elif "Quantity" in df.columns:
            popularity_metric = "Quantity"

        if popularity_metric:
            popularity = df.groupby("Product")[popularity_metric].sum()
            revenue_by_product = df.groupby("Product")["Revenue"].sum()
            profit_by_product = df.groupby("Product")["Profit"].sum()

            most_popular = popularity.idxmax()
            least_popular = popularity.idxmin()

            st.markdown("### üõí Customer Popularity Insights")

            st.success(
                f"""
                ‚≠ê **Most Popular Product:** {most_popular}  
                ‚Ä¢ {popularity_metric}: {popularity[most_popular]:,.0f}  
                ‚Ä¢ Revenue: ‚Çπ {revenue_by_product[most_popular]:,.0f}  
                ‚Ä¢ Profit: ‚Çπ {profit_by_product[most_popular]:,.0f}
                """
            )

            st.warning(
                f"""
                üìâ **Least Popular Product:** {least_popular}  
                ‚Ä¢ {popularity_metric}: {popularity[least_popular]:,.0f}  
                ‚Ä¢ Revenue: ‚Çπ {revenue_by_product[least_popular]:,.0f}  
                ‚Ä¢ Profit: ‚Çπ {profit_by_product[least_popular]:,.0f}
                """
            )

    # =========================
    # ROOT CAUSE ANALYSIS (EXTENDED)
    # =========================
    st.subheader("üß† Root Cause Analysis")

    loss_df = df[df["Profit"] < 0]

    if loss_df.empty:
        st.success("üéâ No major losses detected")
    else:
        # 1Ô∏è‚É£ Product causing maximum loss
        if "Product" in df.columns:
            loss_product = loss_df.groupby("Product")["Profit"].sum().idxmin()
            st.error(f"‚ùå Highest Loss Product: {loss_product}")

        # 2Ô∏è‚É£ Region causing maximum loss
        if "Region" in df.columns:
            loss_region = loss_df.groupby("Region")["Profit"].sum().idxmin()
            st.error(f"üìç Highest Loss Region: {loss_region}")

        # 3Ô∏è‚É£ Date with maximum loss
        if "Date" in df.columns:
            loss_date = (
                loss_df.groupby(pd.to_datetime(loss_df["Date"]))["Profit"]
                .sum()
                .idxmin()
            )
            st.error(f"üìÖ Worst Loss Date: {loss_date.date()}")

        # 4Ô∏è‚É£ Cost-heavy products (Cost >> Revenue)
        cost_imbalance = (
            df.groupby("Product")[["Revenue", "Cost"]]
            .sum()
            .assign(Cost_Ratio=lambda x: x["Cost"] / x["Revenue"])
            .sort_values("Cost_Ratio", ascending=False)
        )

        if not cost_imbalance.empty:
            worst_cost_product = cost_imbalance.index[0]
            st.warning(
                f"üí∏ Cost Inefficiency: {worst_cost_product} "
                f"(Cost is {cost_imbalance.iloc[0]['Cost_Ratio']:.2f}x Revenue)"
            )

        # 5Ô∏è‚É£ High sales but low profit products
        if {"Sales", "Product"}.issubset(df.columns):
            sales_profit_gap = (
                df.groupby("Product")[["Sales", "Profit"]]
                .sum()
                .sort_values("Sales", ascending=False)
            )

            risky_product = sales_profit_gap[sales_profit_gap["Profit"] < 0]

            if not risky_product.empty:
                st.warning(
                    f"‚ö†Ô∏è High Sales but Loss-Making Product: {risky_product.index[0]}"
                )

        # 6Ô∏è‚É£ Region with highest loss ratio
        if "Region" in df.columns:
            region_loss_ratio = (
                df.assign(Is_Loss=df["Profit"] < 0)
                .groupby("Region")["Is_Loss"]
                .mean()
                .sort_values(ascending=False)
            )

            worst_loss_region = region_loss_ratio.index[0]
            st.warning(
                f"üìä Highest Loss Ratio Region: {worst_loss_region} "
                f"({region_loss_ratio.iloc[0]*100:.1f}% loss transactions)"
            )

        # 7Ô∏è‚É£ Anomaly-based RCA
        if "Anomaly" in df.columns and "Product" in df.columns:
            anomaly_products = (
                df[df["Anomaly"] == -1]
                .groupby("Product")
                .size()
                .sort_values(ascending=False)
            )

            if not anomaly_products.empty:
                st.warning(
                    f"üö® Most Anomaly-Prone Product: {anomaly_products.index[0]}"
                )

        # 8Ô∏è‚É£ Low margin products
        margin = (
            df.groupby("Product")[["Revenue", "Profit"]]
            .sum()
            .assign(Margin=lambda x: x["Profit"] / x["Revenue"])
            .sort_values("Margin")
        )

        if not margin.empty:
            st.warning(
                f"üìâ Lowest Margin Product: {margin.index[0]} "
                f"({margin.iloc[0]['Margin']*100:.1f}% margin)"
            )

        # 9Ô∏è‚É£ Region‚ÄìProduct loss combination
        if {"Region", "Product"}.issubset(df.columns):
            combo_loss = (
                loss_df.groupby(["Region", "Product"])["Profit"]
                .sum()
                .sort_values()
            )

            if not combo_loss.empty:
                region, product = combo_loss.index[0]
                st.error(
                    f"üîó Loss Hotspot: {product} in {region}"
                )

        # üîü Sudden cost spikes
        if "Date" in df.columns:
            df["Date"] = pd.to_datetime(df["Date"])
            cost_trend = df.groupby("Date")["Cost"].sum()
            spike = cost_trend[cost_trend > cost_trend.mean() + 2*cost_trend.std()]

            if not spike.empty:
                st.warning(
                    f"‚ö° Sudden Cost Spike Detected on: {spike.index[0].date()}"
                )

        # 1Ô∏è‚É£1Ô∏è‚É£ Revenue drop despite stable sales
        if {"Sales", "Revenue"}.issubset(df.columns):
            corr_sr = df["Sales"].corr(df["Revenue"])
            if corr_sr < 0.3:
                st.warning(
                    "üìâ Revenue is weakly correlated with Sales ‚Äî possible pricing or discount issue"
                )

        # 1Ô∏è‚É£2Ô∏è‚É£ Seasonal loss pattern
        if "Date" in df.columns:
            df["Month"] = pd.to_datetime(df["Date"]).dt.month
            monthly_loss = (
                df.groupby("Month")["Profit"]
                .sum()
                .sort_values()
            )

            if not monthly_loss.empty:
                st.warning(
                    f"üìÜ Worst Performing Month: {monthly_loss.index[0]}"
                )

# =========================
# üî• LOAD FROM HISTORY LINK (FIX)
# =========================
query = st.query_params.get("file")

if query:
    file_name = unquote(query)
    file_path = os.path.join("uploads", file_name)

    if os.path.exists(file_path):
        st.success(f"üìÇ Loaded dataset: {file_name}")
        df = pd.read_csv(file_path) if file_name.endswith(".csv") else pd.read_excel(file_path)
        run_analysis(df)
        st.stop()   # üî¥ STOP further rendering (IMPORTANT)

# =========================
# NAVIGATION
# =========================
menu = st.radio(
    "Navigation",
    ["üè† Home", "üìò Description", "üì§ Upload Dataset", "üïí History"],
    horizontal=True
)

# =========================
# HOME
# =========================
if menu == "üè† Home":
    st.title("üìä Intelligent Root Cause Analysis System")
    st.markdown("""
    Welcome to the **Intelligent RCA System for Business KPIs**.

    üîç Detect profit & loss anomalies  
    üß† Identify root causes  
    üìä Visualize trends  
    üí° Generate business-ready insights  

    üëâ Use the navigation bar above.
    """)

elif menu == "üìò Description":
    st.markdown(
        """
        <h3>‚ö†Ô∏è Important Note</h3>
        <p style="font-size:17px;">
        Please ensure that the uploaded dataset is <b>clean, structured, and error-free</b>.
        Missing values, incorrect data types, or inconsistent entries may affect analysis accuracy.
        </p>
        <h4>Mandatory Columns</h4>
        <ul>
        <li>Revenue</li>
        <li>Cost</li>
        <li>Product</li>
        <li>Region</li>
        <li>Sales</li>
        <li>Date</li>
        </ul>
        """,
        unsafe_allow_html=True
    )

elif menu == "üì§ Upload Dataset":
    file = st.file_uploader("Upload Dataset", type=["csv", "xlsx"])
    if file:
        os.makedirs("uploads", exist_ok=True)
        path = os.path.join("uploads", file.name)
        with open(path, "wb") as f:
            f.write(file.getbuffer())
        save_upload(file.name, path)
        df = pd.read_csv(file) if file.name.endswith(".csv") else pd.read_excel(file)
        run_analysis(df)


# =========================
# HISTORY (COLUMN VIEW)
# =========================
elif menu == "üïí History":
    st.title("üïí Upload History")

    history = fetch_upload_history()

    if not history:
        st.info("No uploaded datasets yet.")
    else:
        c1, c2, c3, c4 = st.columns([3, 2, 2, 2])
        c1.markdown("**Dataset**")
        c2.markdown("**Date**")
        c3.markdown("**Time**")
        c4.markdown("**Action**")

        st.divider()

        for h in history:
            file = quote(h["file_name"])
            c1, c2, c3, c4 = st.columns([3, 2, 2, 2])
            c1.write(h["file_name"])
            c2.write(h["upload_date"])
            c3.write(str(h["upload_time"])[:8])
            c4.markdown(f"[Open Analysis](/?file={file})")